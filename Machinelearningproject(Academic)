                                                              //     ##IMPORTING LIBRARIES   //


import tensorflow as tf
import matplotlib.pyplot as plt import pandas as pd
import seaborn as sns

##DATA PREPROCESSING
## TRAINING IMAGE PREPROCESSING
training_set = tf.keras.utils.image_dataset_from_directory( 'train',
labels="inferred", label_mode="categorical", class_names=None, color_mode="rgb", batch_size=32, image_size=(128, 128), shuffle=True,
seed=None, validation_split=None, subset=None, interpolation="bilinear", follow_links=False, crop_to_aspect_ratio=False
)
training_set
for x,y in training_set: print(x,x.shape) print(y,y.shape) break

                                                          //   ## VALIDATION IMAGE PREPROCESSING   //


validation_set = tf.keras.utils.image_dataset_from_directory( 'valid',
labels="inferred", label_mode="categorical", class_names=None, color_mode="rgb", batch_size=32, image_size=(128, 128), shuffle=True,
seed=None, validation_split=None, subset=None, interpolation="bilinear", follow_links=False, crop_to_aspect_ratio=False
)
validation_set
for x,y in validation_set: print(x,x.shape) print(y,y.shape) break

                                                                      //  ##BUILDING MODE:   //
cnn = tf.keras.models.Sequential()

                                                                  //    ## BUILDING CNN MODEL      //


cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shap e=[128,128,3]))
cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu')) cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu')) cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu')) cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu')) cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu')) cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu')) cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu')) cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu')) cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu')) cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Dropout(0.25)) cnn.add(tf.keras.layers.Flatten()) cnn.add(tf.keras.layers.Dense(units=1500,activation='relu')) cnn.add(tf.keras.layers.Dropout(0.4)) #To avoid overfitting
#Output Layer cnn.add(tf.keras.layers.Dense(units=38,activation='softmax'))


                                                                     //  ## COMPILE AND TRAING PHASE  //
import tensorflow as tf
# Assuming you have defined your CNN model as 'cnn' somewhere in your code # Compile the model
cnn.compile(
optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy',
metrics=['accuracy']
)

                                                                //  # Print the model summary cnn.summary()  //

training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)

                                                                        //   ## EVALUATING MODEL:  //


#Training set Accuracy
train_loss, train_acc = cnn.evaluate(training_set) print('Training accuracy:', train_acc)
#Validation set Accuracy
val_loss, val_acc = cnn.evaluate(validation_set) print('Validation accuracy:', val_acc)




                                                                           //  ## SAVING THE MODEL  //


cnn.save('trained_plant_disease_model.keras')
training_history.history #Return Dictionary of history #Recording History in json
import json
with open('training_hist.json','w') as f: json.dump(training_history.history,f) print(training_history.history.keys())

                                                                       // ## MATRICES FOR MODEL EVALUATION:   //


class_name = validation_set.class_names
test_set = tf.keras.utils.image_dataset_from_directory( 'valid',
labels="inferred", label_mode="categorical", class_names=None, color_mode="rgb", batch_size=1, image_size=(128, 128), shuffle=False, seed=None, validation_split=None, subset=None, interpolation="bilinear", follow_links=False,
crop_to_aspect_ratio=False
)
y_pred = cnn.predict(test_set) predicted_categories = tf.argmax(y_pred, axis=1)
true_categories = tf.concat([y for x, y in test_set], axis=0) Y_true = tf.argmax(true_categories, axis=1)
Y_true predicted_categories
from sklearn.metrics import confusion_matrix,classification_report cm = confusion_matrix(Y_true,predicted_categories)

                                                                            //  # Precision Recall Fscore   //


pr int(classification_report(Y_true,predicted_categories,target_names=class_name))
import matplotlib.pyplot as plt

# Data from the classification report class_name = [
'Apple	Apple_scab', 'Apple	Black_rot', 'Apple	Cedar_apple_rust', 'Apple	healthy', 'Blueberry		healthy',
'Cherry_(including_sour)	Powdery_mildew', 'Cherry_(including_sour)		healthy', 'Corn_(maize)	Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)	Common_rust_', 'Corn_(maize)	Northern_Leaf_Blight', 'Corn_(maize)	healthy', 'Grape		Black_rot', 'Grape	Esca_(Black_Measles)', 'Grape	Leaf_blight_(Isariopsis_Leaf_Spot)',
'Grape	healthy',
'Orange	Haunglongbing_(Citrus_greening)', 'Peach	Bacterial_spot', 'Peach	healthy', 'Pepper,_bell	Bacterial_spot', 'Pepper,_bell_   healthy', 'Potato	Early_blight',
'Potato	Late_blight', 'Potato	healthy'
]

precision = [
0.96, 0.99, 0.98, 0.98, 0.97, 0.99, 0.97, 0.95, 1.00, 0.90, 1.00, 0.99, 0.98, 0.96, 1.00, 0.96, 0.97,
0.98, 0.98,
0.99, 0.93, 0.95
]
recall = [
0.98, 1.00, 0.98, 0.95, 0.96, 0.98, 0.99, 0.84, 1.00, 0.97, 1.00, 0.95, 0.99, 1.00, 1.00, 0.99, 0.93,
0.99, 0.94,
0.98, 0.99, 0.99
]
f1_score = [
0.97, 0.99, 0.98, 0.97, 0.97, 0.99, 0.98, 0.89, 1.00, 0.94, 1.00, 0.97, 0.99, 0.98, 1.00, 0.98, 0.95,
0.99, 0.97,
0.96, 0.96, 0.97
]

# Plotting individual bar charts for each class for i in range(len(class_name)):
fig, ax = plt.subplots(figsize=(10, 5))
bars = ax.bar(['Precision', 'Recall', 'F1-Score'], [precision[i], recall[i], f1_score[i]]) ax.set_title(class_name[i])
plt.ylim(0, 1) # Set y-axis limit to range from 0 to 1 for consistency plt.show()
plt.figure(figsize=(40, 40))
sns.heatmap(cm,annot=True,annot_kws={"size": 10})
plt.xlabel('Predicted Class',fontsize = 20) plt.ylabel('Actual Class',fontsize = 20)
plt.title('Plant Disease Prediction Confusion Matrix',fontsize = 25) plt.show()
# Plotting training and validation accuracy over epochs
plt.plot(epochs, training_history.history['accuracy'], color='red', label='Training Accuracy') plt.plot(epochs, training_history.history['val_accuracy'], color='blue', label='Validation Accuracy') plt.xlabel('No. of Epochs')
plt.title('Visualization of Accuracy Result') plt.legend()
plt.show()

# Plotting training and validation loss over epochs
plt.plot(epochs, training_history.history['loss'], color='red', label='Training Loss') plt.plot(epochs, training_history.history['val_loss'], color='blue', label='Validation Loss') plt.xlabel('No. of Epochs')
plt.title('Visualization of Loss Result') plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix, classification_report import seaborn as sns
import matplotlib.pyplot as plt import numpy as np

# Generate mock data for demonstration np.random.seed(0)
y_true = np.random.randint(0, 2, size=100) # Actual labels (binary classification) y_pred = np.random.randint(0, 2, size=100) # Predicted labels (binary classification)

# Calculate confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Print classification report print(classification_report(y_true, y_pred))

# Plotting confusion matrix using seaborn plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g') plt.xlabel('Predicted Class')
plt.ylabel('Actual Class') plt.title('Confusion Matrix') plt.show()


                                                                          //  ##IMPORTING LIBRARIES  //


import numpy as np import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator import matplotlib.pyplot as plt

                                                                          //  ##TEST SET IMAGE PREPROCESSING  //
validation_set = tf.keras.utils.image_dataset_from_directory( 'valid',
labels="inferred", label_mode="categorical", class_names=None, color_mode="rgb", batch_size=32, image_size=(128, 128), shuffle=True,
seed=None, validation_split=None, subset=None, interpolation="bilinear", follow_links=False, crop_to_aspect_ratio=False
)
class_name = validation_set.class_names print(class_name)

                                                                            //  ## LOADING THE MODEL  //
cnn = tf.keras.models.load_model('trained_plant_disease_model.keras')

                                                          //  ##VISUASLISING AND PERFORMING PREDICTION ON SINGLE IMAGE  //
#Test Image Visualization import cv2
import matplotlib.pyplot as plt

# Define the image path using a raw string literal
image_path = r'C:\Users\nanda\Documents\projectcode\test\AppleCedarRust1.JPG'

##TESTING THE MODEL
# Reading an image in default mode img = cv2.imread(image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Converting BGR to RGB

# Displaying the image plt.imshow(img) plt.title('Test Image') plt.xticks([])
plt.yticks([]) plt.show()




image = tf.keras.preprocessing.image.load_img(image_path,target_size=(128,128)) input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr]) # Convert single image to a batch. predictions = cnn.predict(input_arr)

print(predictions)

result_index = np.argmax(predictions) #Return index of max element print(result_index)

# Displaying the disease prediction model_prediction = class_name[result_index] plt.imshow(img)
plt.title(f"Disease Name: {model_prediction}") plt.xticks([])
plt.yticks([]) plt.show()

5.2.2PREDICTION OF AN IMAGE:
import streamlit as st import tensorflow as tf import numpy as np import pandas as pd

# Tensorflow Model Prediction def model_prediction(test_image):
model = tf.keras.models.load_model("trained_plant_disease_model.keras")
image = tf.keras.preprocessing.image.load_img(test_image, target_size=(128, 128)) input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr]) # convert single image to batch predictions = model.predict(input_arr)
return np.argmax(predictions) # return index of max element

# CSS styling st.markdown("""
<style>
.header-text { font-size: 36px;
color: #2ecc71; /* Green color */ text-align: center;
}
.button {
background-color: #3498db; /* Blue color */ color: white;
padding: 10px 20px; border: none;
border-radius: 5px; cursor: pointer;
transition: background-color 0.3s;
}
.button:hover {
background-color: #2980b9; /* Darker blue on hover */
}
.prediction-text { font-size: 24px;
color: #e74c3c; /* Red color */ text-align: center;
}
.success-text { font-size: 20px;
color: #27ae60; /* Green color */ text-align: center;
margin-top: 20px;
}
.upload-image { margin-top: 20px; text-align: center;
}
.image-preview { margin-top: 20px; display: flex;
justify-content: center;
}
body {
background-color: #f1c40f; /* Yellow background color */ color: #34495e; /* Dark blue text color */
}
</style>
""", unsafe_allow_html=True)

# Sidebar st.sidebar.title("Dashboard")
app_mode = st.sidebar.selectbox("Select Page", ["Home", "About", "Disease Recognition"])

# Main Page
if app_mode == "Home":
st.markdown("<h1 class='header-text'>FLORA DIAGNOSIS SYSTEM</h1>", unsafe_allow_html=True)
st.image("home_page.jpeg", use_column_width=True) st.markdown("""
<div style='text-align: justify;'>
<h3>Welcome to the flora diagnosis System! üåøüîç</h3>
<p>Our mission is to help in identifying plant diseases efficiently. Upload an image of a plant, and our system will analyze it to detect any signs of diseases. Together, let's protect our crops and ensure a healthier harvest!</p>
<h4>How It Works</h4>
<ol>
